{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Clustering\n",
    "\n",
    "Clustering is an interesting field of Unsupervised Machine learning where we classify \n",
    "datasets into set of similar groups. It is part of ‘Unsupervised learning’ meaning, where\n",
    "there is no prior training happening and the dataset will be unlabeled. Clustering can be\n",
    "done using different techniques like K-means clustering, Mean Shift clustering, DB Scan \n",
    "clustering, Hierarchical clustering etc. \n",
    "\n",
    "###### Image clustering\n",
    "\n",
    "\n",
    "Image clustering is an essential data analysis tool in machine\n",
    "learning and computer vision. Many applications\n",
    "such as content-based image annotation and\n",
    "image retrieval can be viewed as different instances\n",
    "of image clustering. Technically, image clustering\n",
    "is the process of grouping images into clusters such that the\n",
    "images within the same clusters are similar to each other,\n",
    "while those in different clusters are dissimilar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Code: import Kmeans library from sklearn ( 1 point)\n",
    "from sklearn.cluster import KMeans\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### VGG \n",
    "\n",
    "VGG is a convolutional neural network model for image recognition proposed by the Visual Geometry Group in the University of Oxford, where VGG16 refers to a VGG model with 16 weight layers, and VGG19 refers to a VGG model with 19 weight layers. The architecture of VGG16: the input layer takes an image in the size of (224 x 224 x 3), and the output layer is a softmax prediction on 1000 classes. From the input layer to the last max pooling layer (labeled by 7 x 7 x 512) is regarded as the feature extraction part of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimensions:  4\n",
      "shape:  (1, 7, 7, 512)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "model = VGG16(weights='imagenet', include_top=False)    \n",
    "\n",
    "img_path = ('/Users/pramanikpramanik/Desktop/Machine Learning/dataset/train_dataset/african-lionadapt19001JPG.jpg')\n",
    "# Code: Specify path of the random image from the training dataset. (1 point)\n",
    "img = image.load_img(img_path, target_size=(224, 224)) \n",
    "img_data = image.img_to_array(img)\n",
    "img_data = np.expand_dims(img_data, axis=0)\n",
    "\n",
    "vgg16_feature = model.predict(img_data)  \n",
    "\n",
    "\n",
    "print('dimensions: ',np.ndim(vgg16_feature))\n",
    "print('shape: ',np.shape(vgg16_feature))\n",
    "\n",
    "# Code: print the shape of the vgg16_feature  (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The given function will extract the features from the images.\n",
    "\n",
    "# 2 changes - one for importing file and handling exceptions, another for adding filenames and returing the array.\n",
    "\n",
    "def extract_feature(directory):\n",
    "    vgg16_feature_list = []\n",
    "    filename_arr = [] # extra for saving filenames\n",
    "    for filename in os.listdir(directory):\n",
    "      if not filename.endswith('.DS_Store'): # adding extra code for mac os \n",
    "          try:  \n",
    "            #print (filename)\n",
    "            img = image.load_img(os.path.join(directory,filename), target_size=(224, 224))\n",
    "            filename_arr.append(filename) \n",
    "            # extra code for saving filenames to be used later to copy image to respective cluster folders\n",
    "            img_data = image.img_to_array(img)\n",
    "            img_data = np.expand_dims(img_data, axis=0)\n",
    "            img_data = preprocess_input(img_data)\n",
    "\n",
    "            vgg16_feature = model.predict(img_data)\n",
    "            vgg16_feature_np = np.array(vgg16_feature)\n",
    "            vgg16_feature_list.append(vgg16_feature_np.flatten())\n",
    "          except:\n",
    "            pass\n",
    "    vgg16_feature_list_np = np.array(vgg16_feature_list)\n",
    "    filename_arr_np = np.array(filename_arr)\n",
    "    \n",
    "    return vgg16_feature_list_np,filename_arr_np # returning filenames array as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The given dataset has three classes that are: Lion , Fish and Zebra, but we are not providing any \n",
    "    supervision to the model i.e. we are not specifying which image is associated with which\n",
    "    class / cluster. For this we using unsupervised image clustering to create the clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pramanikpramanik/opt/anaconda3/lib/python3.7/site-packages/PIL/Image.py:2817: UserWarning: image file could not be identified because WEBP support not installed\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "       n_clusters=3, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "       random_state=0, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature_vector, f_train = extract_feature(\"/Users/pramanikpramanik/Desktop/Machine Learning/dataset/train_dataset\")  \n",
    "# pass the path of the folder where you have the training dataset\n",
    "\n",
    "kmeans_model = KMeans(n_clusters=3, random_state=0)\n",
    "# Code: create the kmeans object and initialize it with the number_of_clusters = 3   (2 point)\n",
    "kmeans_model.fit(train_feature_vector) \n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a test vector using extract_feature function. It will return a feature vector of size \n",
    "# number of images * size of the feature vector\n",
    "\n",
    "# retruning extra array for file names\n",
    "test_vector, f_test = extract_feature('/Users/pramanikpramanik/Desktop/Machine Learning/dataset/test_dataset')  # (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimensions:  2\n",
      "shape:  (32, 25088)\n"
     ]
    }
   ],
   "source": [
    "# Code: print the shape of the test vector   # (1 point)\n",
    "print('dimensions: ',np.ndim(test_vector))\n",
    "print('shape: ',np.shape(test_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 1 2 0 0 0 0 0 0 2 2 2 0 2 0 0 0 0 0 0 0 0 0 0 2 0 0 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "labels = kmeans_model.predict(test_vector)\n",
    "print(labels)\n",
    "# Code: use the kmeans model to predict the labels for the test vector (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code: Using the labels and the images, save the test images in the different folders in respective \n",
    "# clusters.   (2 point)\n",
    "\n",
    "# added extra code while generating features to save filenames to be referred here.\n",
    "\n",
    "# folders has been names 0/1/2 because not sure which one is zebra/fish/lion\n",
    "# after copying - 0 is fish, 1 is zebra, 2 is lion\n",
    "\n",
    "from shutil import copyfile\n",
    "label_len = len(labels)\n",
    "testhome = '/Users/pramanikpramanik/Desktop/Machine Learning/dataset/'\n",
    "for i in range(label_len):\n",
    "    copyfile(testhome+'test_dataset/'+str(f_test[i]), testhome+'/result/'+str(labels[i])+'/'+f_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
